{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 478 Machine Learning\n",
    "\n",
    "\n",
    "## Getting Started with Tensorflow, Keras, and Tensorboard\n",
    "\n",
    "### Instructor: Fereydoon Vafaei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brian J. Stout AK37018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps you get started with Tensorflow/Keras API. **READ ALL SECTIONS VERY CAREFULLY!**\n",
    "\n",
    "**Note**: You should install Tensorflow 2 before starting this notebook.<br> If you have not installed Tensorflow 2 or have installed previous versions of Tensorflow, you need to [install Tensorflow 2](https://www.tensorflow.org/install) before proceeding. Alternatively, you can install Tensorflow 2 using [conda environment](https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/). CPU-only TensorFlow is sufficient for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO.\n",
    "\n",
    "<b>Course Policy Reminder:</b>\n",
    "Debugging and error resolution are always students' responsbility. This policy will be enforced in email communications and the office hours. Keep in mind that all assignments are individual graded tasks. Any collaboration with other students is strictly prohibited and is considered as cheating. Students should NOT share any answer, solution, or code with other students. Violations of these policies would be penalized according to UMBC academic integrity policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Installation Verification](#Installation-Verification)\n",
    "* [A Simple Regression NN](#A-One-Layer-One-Neuron-Regression-Neural-Network-using-Tensorflow/Keras)\n",
    "* [A Multi-layer NN on MNIST Dataset](#A-Multi-Layer-NN-for-Multi-Class-Classification-on-MNIST-Dataset)\n",
    "* [Eager Execution in Tensorflow-2](#Eager-Execution-in-Tensorflow-2)\n",
    "* [Creating the model using the Sequential API](#Creating-the-model-using-the-Sequential-API)\n",
    "* [Fashion MNIST Dataset](#Fashion-MNIST-Dataset)\n",
    "* [California House Pricing](#California-House-Pricing)\n",
    "* [Saving and Restoring the Models](#Saving-and-Restoring-the-Models)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Tensorboard](#Tensorboard)\n",
    "* [Exercise-1](#Exercise-1)\n",
    "* [Exercise-2](#Exercise-2)\n",
    "* [References](#References)\n",
    "* [Grading and Submission](#Grading-and-Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is one of the most popular ML/DL frameworks. Watch this video first:\n",
    "\n",
    "https://www.youtube.com/watch?v=744f60NyAgc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify your installation using the following cells.\n",
    "\n",
    "**Note**: It is recommended that you install (or upgrade to) the latest stable version of tensorflow 2. While the minimum requirement for tf version for this notebook is 2.0.0 (which is needed to run the textbook and slides codes), it is your responsibility to update tf to the latest stable version for the assignments when/if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your tf/keras version should be 2.x.x (latest stable version is recommended)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check that all important packages can be imported. \n",
    "# Note: If you use a separate conda environment for tf, you may need to reinstall some of these libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A One-Layer One-Neuron Regression Neural Network using Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first example is a regression NN with only one layer and one neuron to recognize the pattern of a sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 39.8674\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.7201\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.3029\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.2471\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.2624\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.1206\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6421\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6856\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1399\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9175\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9496\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1821\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5723\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0868\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6991\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3885\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1388\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9369\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7729\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6387\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5282\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4363\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3592\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2938\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2378\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1892\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1465\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1086\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0746\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0436\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0152\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9888\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9642\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9410\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9190\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8980\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8779\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8586\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8399\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8218\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8043\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7873\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7707\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7546\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7389\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7235\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7085\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6938\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6795\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6654\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6517\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6383\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6251\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6123\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5997\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5873\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5752\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5634\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5518\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5405\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5294\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5185\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5079\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4872\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4772\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4578\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4484\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4392\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4302\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4213\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4127\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4042\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3959\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3878\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3798\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3720\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3643\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3569\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3495\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.3424\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3353\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3284\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3217\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3151\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3086\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3023\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2961\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2900\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2840\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2782\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2725\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2669\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2614\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2560\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2508\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2456\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2406\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2356\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2308\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2260\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2214\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2169\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2124\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2080\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2038\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1996\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1955\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1915\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1875\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1837\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1799\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1762\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1726\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1690\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1656\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1622\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1588\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1556\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1524\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1493\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1462\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1432\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1402\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1374\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1345\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1318\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1264\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1238\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1213\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1188\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1164\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1140\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1116\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1093\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1049\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1027\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1006\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0986\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0965\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0945\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0926\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0907\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0888\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0870\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0852\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0835\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0818\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0801\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0784\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0768\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0737\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0722\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0707\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0693\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0678\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0651\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0637\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0599\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0587\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0563\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0551\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0540\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0529\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0518\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0507\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0497\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0487\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0477\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0467\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0457\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0448\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0439\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0430\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0421\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0412\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0404\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0395\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0387\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0379\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0349\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0342\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0335\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0328\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0321\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0290\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0284\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0278\n",
      "Epoch 204/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0272\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0267\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0261\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0256\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0250\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0245\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0240\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0235\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0231\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0226\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0221\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0217\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0199\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0195\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0187\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0134\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0132\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0129\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0126\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0124\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0119\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0116\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0111\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0107\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0105\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0082\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0077\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0074\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0065\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0064\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0061\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0054\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0053\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0052\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0051\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0049\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0045\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 305/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0031\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0024\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0020\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0010\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8321e-04\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6302e-04\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4324e-04\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2386e-04\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0488e-04\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8629e-04\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6809e-04\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5026e-04\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3280e-04\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1569e-04\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9894e-04\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8252e-04\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6645e-04\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5071e-04\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.3529e-04\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2018e-04\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0539e-04\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9090e-04\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7671e-04\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.6281e-04\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4920e-04\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3586e-04\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.2280e-04\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1000e-04\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9747e-04\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.8520e-04\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7318e-04\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6141e-04\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4988e-04\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.3858e-04\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2752e-04\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1668e-04\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0607e-04\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9568e-04\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8550e-04\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7552e-04\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6575e-04\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5619e-04\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.4682e-04\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3764e-04\n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2865e-04\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1985e-04\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1122e-04\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0278e-04\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9450e-04\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8640e-04\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7846e-04\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7069e-04\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6308e-04\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5562e-04\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4831e-04\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4116e-04\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3415e-04\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2729e-04\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2056e-04\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1398e-04\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0753e-04\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0121e-04\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9502e-04\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8896e-04\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8303e-04\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7722e-04\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7152e-04\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6594e-04\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6048e-04\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5513e-04\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4989e-04\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4476e-04\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3973e-04\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3481e-04\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2998e-04\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2526e-04\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2063e-04\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1610e-04\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1166e-04\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0731e-04\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0306e-04\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9889e-04\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9480e-04\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9080e-04\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8688e-04\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8304e-04\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7928e-04\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7560e-04\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7199e-04\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6846e-04\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6500e-04\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6161e-04\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5829e-04\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5504e-04\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5185e-04\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4873e-04\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4568e-04\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4269e-04\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3976e-04\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3689e-04\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3408e-04\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3132e-04\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2863e-04\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2598e-04\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2340e-04\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2086e-04\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1838e-04\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1595e-04\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1356e-04\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1123e-04\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0895e-04\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0671e-04\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0452e-04\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0237e-04\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0027e-04\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8210e-05\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6192e-05\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4216e-05\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2279e-05\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0385e-05\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8529e-05\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6710e-05\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4929e-05\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3185e-05\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1475e-05\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9801e-05\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8161e-05\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6557e-05\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4984e-05\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3443e-05\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1935e-05\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0458e-05\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9011e-05\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7593e-05\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6204e-05\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4845e-05\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3512e-05\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2208e-05\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0930e-05\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9679e-05\n",
      "Epoch 500/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8453e-05\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7253e-05\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6077e-05\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4925e-05\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3797e-05\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2692e-05\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1610e-05\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0550e-05\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9511e-05\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8494e-05\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7498e-05\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6523e-05\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5567e-05\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4631e-05\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3715e-05\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2817e-05\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1937e-05\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1075e-05\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0232e-05\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9406e-05\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8597e-05\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7804e-05\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7027e-05\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6267e-05\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5522e-05\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4792e-05\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4078e-05\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3378e-05\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2692e-05\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2020e-05\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1363e-05\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0719e-05\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0087e-05\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9470e-05\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8864e-05\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8271e-05\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7690e-05\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7122e-05\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6564e-05\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6018e-05\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5484e-05\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4960e-05\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4448e-05\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3946e-05\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3454e-05\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2972e-05\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2500e-05\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.2039e-05\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1585e-05\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1142e-05\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0708e-05\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0283e-05\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9866e-05\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9458e-05\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9058e-05\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8667e-05\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8283e-05\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7908e-05\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7539e-05\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7179e-05\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6826e-05\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6481e-05\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6142e-05\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5811e-05\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5487e-05\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5168e-05\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4856e-05\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4551e-05\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4253e-05\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3960e-05\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3673e-05\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3393e-05\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3118e-05\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2848e-05\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2584e-05\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2326e-05\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2072e-05\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1825e-05\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1582e-05\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1343e-05\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1110e-05\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0882e-05\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0658e-05\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0440e-05\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0225e-05\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0015e-05\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8098e-06\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6080e-06\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.4108e-06\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2172e-06\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0280e-06\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8425e-06\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6612e-06\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4830e-06\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3092e-06\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1385e-06\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9711e-06\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8074e-06\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6469e-06\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.4902e-06\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3362e-06\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1856e-06\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0383e-06\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8937e-06\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7518e-06\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6136e-06\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4774e-06\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3447e-06\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2140e-06\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0868e-06\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9614e-06\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8388e-06\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7194e-06\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6017e-06\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4865e-06\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3737e-06\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2633e-06\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1551e-06\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0495e-06\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9458e-06\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8442e-06\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7447e-06\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6468e-06\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5513e-06\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4578e-06\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3662e-06\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2767e-06\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1889e-06\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1030e-06\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0185e-06\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9359e-06\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8553e-06\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7758e-06\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6984e-06\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6224e-06\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5479e-06\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4750e-06\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4035e-06\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3340e-06\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2653e-06\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1982e-06\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1324e-06\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0681e-06\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0051e-06\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9435e-06\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8831e-06\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8237e-06\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7655e-06\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7088e-06\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6531e-06\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5984e-06\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5452e-06\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4929e-06\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4416e-06\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3916e-06\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3423e-06\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2942e-06\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2471e-06\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2009e-06\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1558e-06\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1116e-06\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0680e-06\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0256e-06\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9840e-06\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9431e-06\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9032e-06\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8640e-06\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8259e-06\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7885e-06\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7518e-06\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7156e-06\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6805e-06\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6460e-06\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6122e-06\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5791e-06\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5467e-06\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5148e-06\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4838e-06\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4535e-06\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4235e-06\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3941e-06\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3657e-06\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3375e-06\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3100e-06\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2832e-06\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2569e-06\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2309e-06\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2056e-06\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1809e-06\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1566e-06\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1329e-06\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1096e-06\n",
      "Epoch 692/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0867e-06\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0645e-06\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0426e-06\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0212e-06\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0003e-06\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7967e-07\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5965e-07\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3991e-07\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2055e-07\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0177e-07\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8324e-07\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6496e-07\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4732e-07\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2986e-07\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1285e-07\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9608e-07\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7981e-07\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6377e-07\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4793e-07\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3271e-07\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1770e-07\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0297e-07\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8847e-07\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7437e-07\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6053e-07\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4706e-07\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3379e-07\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2063e-07\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0799e-07\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9537e-07\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8326e-07\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7125e-07\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5947e-07\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4802e-07\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3679e-07\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2575e-07\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1492e-07\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.0429e-07\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9391e-07\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8382e-07\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7386e-07\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6409e-07\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5467e-07\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4533e-07\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3615e-07\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2718e-07\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1836e-07\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0980e-07\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0143e-07\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9321e-07\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8506e-07\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7717e-07\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6938e-07\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6183e-07\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5447e-07\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4718e-07\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4004e-07\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3297e-07\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2620e-07\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1953e-07\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1288e-07\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0650e-07\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0018e-07\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9409e-07\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8805e-07\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8209e-07\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7626e-07\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7064e-07\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6512e-07\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5963e-07\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5433e-07\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4905e-07\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4392e-07\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3896e-07\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3406e-07\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2922e-07\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2456e-07\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1993e-07\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1538e-07\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1097e-07\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0662e-07\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0243e-07\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9828e-07\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9421e-07\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9023e-07\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8634e-07\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8248e-07\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7869e-07\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7505e-07\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7151e-07\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6797e-07\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6449e-07\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6115e-07\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5779e-07\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5459e-07\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5140e-07\n",
      "Epoch 788/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4833e-07\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4530e-07\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4231e-07\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3935e-07\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3653e-07\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3366e-07\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3095e-07\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2828e-07\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2564e-07\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2307e-07\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2056e-07\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1807e-07\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1564e-07\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1327e-07\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1095e-07\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0865e-07\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0645e-07\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0426e-07\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0208e-07\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0002e-07\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7966e-08\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5944e-08\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3946e-08\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2062e-08\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0122e-08\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8314e-08\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6467e-08\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4724e-08\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2979e-08\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1274e-08\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9583e-08\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.7962e-08\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6368e-08\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4796e-08\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3252e-08\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1775e-08\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0272e-08\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8833e-08\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7427e-08\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6020e-08\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4690e-08\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3371e-08\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2034e-08\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0797e-08\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9520e-08\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8288e-08\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7102e-08\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5936e-08\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4797e-08\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3648e-08\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2574e-08\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1495e-08\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0414e-08\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9425e-08\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8394e-08\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7396e-08\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6442e-08\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5507e-08\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4566e-08\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3656e-08\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2756e-08\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1885e-08\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1008e-08\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0149e-08\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9355e-08\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8513e-08\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7744e-08\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6959e-08\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6184e-08\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5455e-08\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4733e-08\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4024e-08\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3329e-08\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2641e-08\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1964e-08\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1295e-08\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0644e-08\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0021e-08\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9405e-08\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8829e-08\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8226e-08\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7633e-08\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7086e-08\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6520e-08\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5980e-08\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5430e-08\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4911e-08\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4404e-08\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3905e-08\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3430e-08\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2936e-08\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2459e-08\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2010e-08\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1563e-08\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1115e-08\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0680e-08\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0259e-08\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9853e-08\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9446e-08\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9033e-08\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8654e-08\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8282e-08\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7908e-08\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7513e-08\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7161e-08\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6807e-08\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6462e-08\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6139e-08\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5804e-08\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5466e-08\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5138e-08\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4843e-08\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4537e-08\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4241e-08\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3945e-08\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3653e-08\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3373e-08\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3114e-08\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2857e-08\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2582e-08\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2318e-08\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2072e-08\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1832e-08\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1594e-08\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1356e-08\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1126e-08\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0899e-08\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0673e-08\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0451e-08\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0237e-08\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0021e-08\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8081e-09\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6008e-09\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4094e-09\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2264e-09\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0279e-09\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.8463e-09\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6638e-09\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4878e-09\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3148e-09\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1347e-09\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9680e-09\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8134e-09\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6646e-09\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5052e-09\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3426e-09\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1936e-09\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0566e-09\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9159e-09\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7668e-09\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6292e-09\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4927e-09\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3672e-09\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2355e-09\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1080e-09\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9794e-09\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8590e-09\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7374e-09\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6148e-09\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5088e-09\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3936e-09\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2744e-09\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1592e-09\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0625e-09\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9516e-09\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8565e-09\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7589e-09\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6620e-09\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5554e-09\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4770e-09\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3875e-09\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2963e-09\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2094e-09\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1228e-09\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0344e-09\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9482e-09\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8791e-09\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7953e-09\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7272e-09\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6414e-09\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5750e-09\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4947e-09\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4313e-09\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3644e-09\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2901e-09\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2231e-09\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1620e-09\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1015e-09\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0364e-09\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9768e-09\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9182e-09\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8595e-09\n",
      "Epoch 980/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8023e-09\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7450e-09\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6887e-09\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6324e-09\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5775e-09\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5226e-09\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4717e-09\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4208e-09\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3677e-09\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3188e-09\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2777e-09\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2260e-09\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1753e-09\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1357e-09\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0891e-09\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0409e-09\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0070e-09\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9601e-09\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9244e-09\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8851e-09\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8432e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238795b8ca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple linear regression NN with one layer\n",
    "\n",
    "# build a one-layer one-neuron NN\n",
    "layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([layer_1])\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # 'mse'\n",
    "\n",
    "# data: y = 2x - 1\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float) \n",
    "\n",
    "# train NN\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred when x=10.0 [[18.999878]]\n",
      "Parameters: [array([[1.999982]], dtype=float32), array([-0.9999437], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# using NN, predict y when x=10.0\n",
    "print(\"y_pred when x=10.0\", model.predict([10.0]))\n",
    "\n",
    "print(\"Parameters: {}\".format(layer_1.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Multi-Layer NN for Multi-Class Classification on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the samples from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14901961, 0.74901961, 0.54117647, 0.09411765, 0.09411765,\n",
       "        0.42352941, 0.54117647, 0.13333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2745098 , 0.98823529, 0.98823529, 0.99215686, 0.98823529,\n",
       "        0.98823529, 0.98823529, 0.98823529, 0.63529412, 0.34509804,\n",
       "        0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.94117647, 0.98823529, 0.99215686, 0.94117647,\n",
       "        0.71764706, 0.71764706, 0.96470588, 0.99215686, 0.98823529,\n",
       "        0.79215686, 0.55686275, 0.02745098, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14509804, 0.38431373, 0.82745098, 0.80784314,\n",
       "        0.        , 0.        , 0.16470588, 0.42745098, 0.69411765,\n",
       "        0.98823529, 0.98823529, 0.82745098, 0.16862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.07058824,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.21176471, 0.70196078, 0.98823529, 0.8627451 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16862745, 0.94509804, 1.        , 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.90196078, 0.99215686, 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26666667, 0.96470588, 0.96862745, 0.2627451 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5254902 , 0.98823529, 0.36862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45490196, 0.97254902, 0.78431373, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.38039216,\n",
       "        0.87058824, 0.75294118, 0.04313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14901961, 0.38823529, 0.81568627, 0.89019608,\n",
       "        0.68235294, 0.06666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.81176471, 0.98823529, 0.92941176, 0.34509804,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31372549, 0.79215686, 0.99215686, 0.95686275,\n",
       "        0.81176471, 0.31372549, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04313725, 0.37647059, 0.98823529,\n",
       "        0.98823529, 0.95686275, 0.28627451, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
       "        0.78039216, 0.97647059, 0.99215686, 0.50196078, 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4627451 , 0.97254902, 0.99215686, 0.44313725,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.45098039, 0.99215686, 0.94117647,\n",
       "        0.19607843, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.98823529,\n",
       "        0.27058824, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.90588235,\n",
       "        0.14509804, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-layer NN for multi-class classification\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer - Use Flatten to make it a 1D vector\n",
    "  tf.keras.layers.Dense(128, activation='relu'), # hidden layer with 128 neurons\n",
    "  tf.keras.layers.Dropout(0.2), # dropout is a regularization technique\n",
    "  tf.keras.layers.Dense(10, activation='softmax')]) # output layer has 10 neurons and softmax activation function\n",
    "\n",
    "# compile model for multi-class classification\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # loss='SparseCategoricalCrossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Notes**:\n",
    "\n",
    "> These classifiers process vectors, which are 1D, whereas the current input is a rank-3 tensor (60000, 28, 28). To bridge the gap, we flatten the 3D inputs to 1D with a `Flatten` layer before adding the `Dense` layers.\n",
    "\n",
    "> Use `loss='sparse_categorical_crossentropy'` loss function when there are two or more label classes. `tf` expects labels to be provided as integers. If you want to provide labels using `one-hot` representation, use `CategoricalCrossentropy` loss.\n",
    "\n",
    "> Read more about the [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) and [`CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in their tf documentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.2971 - accuracy: 0.9144\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 982us/step - loss: 0.1431 - accuracy: 0.9567\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 940us/step - loss: 0.1086 - accuracy: 0.9675\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 877us/step - loss: 0.0879 - accuracy: 0.9733\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 934us/step - loss: 0.0759 - accuracy: 0.9768\n",
      "313/313 - 0s - loss: 0.0738 - accuracy: 0.9769 - 298ms/epoch - 952us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07384899258613586, 0.9768999814987183]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# test NN\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution in Tensorflow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2 has this new capability of [\"Eager Execution\"](https://www.tensorflow.org/guide/eager) which makes it more convenient to work with tensors and graph computations. See examples below and compare it with tensorflow 1 which uses Session() and Run() to execute these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.Variable(4, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'x:0' shape=() dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'y:0' shape=() dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(x.numpy())\n",
    "print(y.numpy())\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s review the steps in building a neural network! Here is a classification MLP with two hidden\n",
    "layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a NN for MNIST\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # the input layer\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # the first hidden layer with 300 neurons\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # the 2nd hidden layer with 100 neurons\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # the output layer: it's a 10-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through this code line by line:\n",
    "- The first line creates a Sequential model. This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. This is called the Sequential API.\n",
    "\n",
    "- Next, we build the first layer and add it to the model. It is a `Flatten` layer whose role is to convert each input image into a 1D array: if it receives input data X , it computes `X.reshape(-1, 1)`. This layer does not have any parameters; it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the `input_shape` , which doesn’t include the batch size, only the shape of the instances. Alternatively, you could add a `keras.layers.InputLayer` as the first layer, setting `input_shape=[28,28]`\n",
    "\n",
    "- Next we add a `Dense` hidden layer with 300 neurons. It will use the ReLU activation function. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes Equation 10-2.\n",
    "\n",
    "$$h_{\\mathbf{W}, \\mathbf{b}}(\\mathbf{X}) = \\phi (\\mathbf{X} \\mathbf{W} + \\mathbf{b})$$\n",
    "\n",
    "- Then we add a second `Dense` hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "\n",
    "- Finally, we add a `Dense` output layer with 10 neurons (one per class), using the\n",
    "softmax activation function (because the classes are exclusive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Specifying `activation=\"relu\"` is equivalent to specifying `activation=keras.activations.relu`. Other activation functions are available in the keras.activations package. See https://keras.io/activations/ for the full list.\n",
    "\n",
    "> Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is [another example of image classification](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "26435584/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-class classification NN\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')]) # the output layer has 10 neurons and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.5058 - accuracy: 0.8244 - val_loss: 0.3904 - val_accuracy: 0.8598\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 2s 986us/step - loss: 0.3797 - accuracy: 0.8630 - val_loss: 0.3700 - val_accuracy: 0.8643\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 2s 957us/step - loss: 0.3398 - accuracy: 0.8769 - val_loss: 0.3511 - val_accuracy: 0.8727\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3136 - accuracy: 0.8852 - val_loss: 0.3407 - val_accuracy: 0.8752\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 2s 970us/step - loss: 0.2955 - accuracy: 0.8903 - val_loss: 0.3300 - val_accuracy: 0.8790\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 2s 954us/step - loss: 0.2801 - accuracy: 0.8967 - val_loss: 0.3268 - val_accuracy: 0.8828\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2680 - accuracy: 0.9012 - val_loss: 0.3504 - val_accuracy: 0.8783\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 2s 995us/step - loss: 0.2561 - accuracy: 0.9048 - val_loss: 0.3187 - val_accuracy: 0.8893\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2466 - accuracy: 0.9095 - val_loss: 0.3201 - val_accuracy: 0.8860\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2367 - accuracy: 0.9124 - val_loss: 0.3168 - val_accuracy: 0.8898\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `fit()` method returns a History object containing the training parameters `history.params`, the list of epochs it went through `history.epoch`, and most importantly a dictionary `history.history` containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 10, 'steps': 1688}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you use this dictionary to create a pandas `DataFrame` and call its `plot()` method, you get the learning curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6fklEQVR4nO3de3xcdYH//9dnbsnknrRp2qR3binQlkILWAUC7BdQuSiKgIjSRVlEYMVVEa/sgrsuiLteEGRZQFZY4Aeyi4C4II0IFGxBoJSWUtrSptekuU5uc/v8/jiTyUwySaZtmpNO3s/HYx5zzud8zplPTtq85/M5N2OtRURERNzjcbsBIiIiE53CWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlI4axMeYeY8xuY8zbQyw3xpifGWM2GGPeMsYcO/rNFBERyV3Z9IzvA84aZvlHgcMSryuAO/a/WSIiIhPHiGFsrX0BaB6mynnA/dbxClBmjJk2Wg0UERHJdaNxzLgG2Joy35AoExERkSz4RmEbJkNZxntsGmOuwBnKJhgMHjdjxoxR+HhHPB7H49H5aGNB+3psaD+PDe3nsaH97Fi/fn2TtbZyYPlohHEDkJqq04HtmSpaa+8C7gJYvHixXbVq1Sh8vKO+vp66urpR254MTft6bGg/jw3t57Gh/ewwxnyQqXw0vqY8AXw+cVb1iUCbtXbHKGxXRERkQhixZ2yM+W+gDphsjGkAfgD4Aay1dwJPAx8DNgBdwLID1VgREZFcNGIYW2svHmG5Bb4yai0SERGZYHQ0XURExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUREXKYwFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGX+dxugIiI5BBrIRaBWC9EwxDtgVgvBZ1bYefbEI/2v2KRDPMRiMdSlo00vzfrZvjcker+w7uQX3LAd5vCWETkYBePJ8KvF2KJAIyGhy+L9vYH5ohl4cR0T//0oG2mrIMd1MTjAVaO4s9sPODxg8cHXp/znml+0DI/+IMjrDtg2RhQGIuIpEr27MJObykWSZmPOu9pZcPVSZ0PQyw6ettNDcl4ZHR+duMBbx74Aon3/JTpQGI+H/JLwds3n5eYzksp61sn8fLm8c6773Hk/IXZBeigQPWDx9u/zOMDT24dZVUYi4g7rB0cKskeVjhDWW+G3t6A9yG3l+E9FoZomKU9nbCCRPglQu9A8vic0OoLmb6Xx++Uewcs9xdkruPLTw/JQYGYKSRTyhIhmbbce+AiYXdrPUceWXfAtn+wUxiLiHOsLNIFke6U99TXwGVd6cuiPYmynmGDb1DZqDEp4RIY4j0P/GWJ4Olf1ririZoZszMHojfQH55ef4b51HX82dUxZhR/bskVCmOR8Sweh+hwgdiTXVhGulO2k6HevgSj8Ti9Nn/QefmC4M9PCb7SoUMxrceWGqKBDGXDrNs37fHtc8i9V19PTV3dPq0rMloUxiLDSZ4Y09N/AkvyPTxgPkOd2MA6md4zLzsp3AX1+9h7TIZkSlj6CyCvGIqqBgRohnoZ34PpdbwB9fJGkbUW29NDrL2dWFsb8fb2xHQ78fY2Ym2J+fY2bG8Y4/M5r4AffD6Mz99f5vc5ZX5/f7nfWZas6/cny9LL+9brK0+v17cMvx9zAH7/Nh7HRqPYcAQbCWMjEYhEsANf0Wj6fDhDneQrjI1GB29nuHUS25/94AN4CgpG/eccSGEsBydrneDqDUG4I/Ee6n9Pne7tGDH40t5jvelhur9Sj9clj9vl9c8HCqFgUvpyXx7bdjQx85AjnLKsw7LAWV8h6QprLba7Oz1EE9Ox9kTApoRqPDndTrytzQmeYXiKi/GWlGDy87HRCESiTmj0vRIhwgjbGTVeb39I+3wQ8Kd/KfD5wO+EfHlHB5t+/othAjPR9ugBOmZvDCYQSHwJGfyi70uI34/Jz8PjL8L4A87fmjGgMJaxYa0TcH3hOGRwDgjXcOfg+n3vNpbdZ/vyE73AIQIxLQj7wzA9HDOtO8SyvrNJ+06w2cezPjfW1zNzwPCptRYG9ggiEWxXBBtpwUYbM3zbD2f8w0dq72LYXkXqH8sM20hZN/kHL+3lxxMIgN95N/6By506JhBwlve9/EMs9/szrJ+63v712Ky1xDu7hgnSYUK1o2P4IDQmGajekhI8pSXkVVU586UleEpKU6ZL8JaU4i1N1C0uxni9Wf8MxGLpIR2JOP92kmXRRKBHBpX1haKzXt86KetH+oM/WR4Z+KVgQHkkgm/yZOd3mQxAf3/vfYiQTL761vP5MgRp6nygv35q3Sz3nVsUxjKyaBi6mqCzEbr2ULl7Bfy1YS+Cs8NZlu1Zqt48yCuCQJEzrBoohPwyKJ0OgeKUZYn31Om84sHLRjhD1FqbeRgs06sn0v8HKhLBRtqxkT3DB15a/exfk0Mh1ns9MCAoD5iR/hj6+/8YeoryM/YssNYJ53A47RXv7MJGIkQjYeLhcMY6o9kDGT6w/Xj8iYD3ByhrbGTTL+8g3tbWH6jD9c48HrzFxXhKS5Oh6q+udoIzQ5B6SkrwlpY66xQXY8bgkhxjTGLYefz8id9YX88xOjY/pPHzm5KxkwzX/oDtn26Czj0p003YnnZsDOJRD/Go4dC4oedlwIK1Bowf6w1ivQXgy8d6glhvPninYL0zwZOH9fuxnjzwBLDGuWzDGucFXqzxYfE60xbnW31vDNsVhWgMG4thY1GIxZ33aCs2ticx7SwnllIvOmA6U28ypbdwQBgz7Lf8tPDLC+ApKuzvIfh8tDc3M2nGjMw9hMQ3/qEDtG84bnAvIuMQnc93QI7/ZSvZ4w+nhHUkPCiwbdj50hNPzg8I9ZR1hqyT8gUhHmnF09mFd/p0AtNrBodoas+0r7ywcEwCVSYWhXEuiIadQE30Xm2oCdu2k3jzTuItu4m3NhFvbyHe0UK8o4N4dzfxiBOs8YghFvVgo4ZY1Es8HiAe8xGPep27w4XLiIeLIZ5NryUGdCZe+8HrdYaUfD5M33SyzIvx+tKm8XoGlZlAnjPtSZQN6t1lMRw2MKwyhl3m+qMxLPZefT3HTpCehDEm+cXCU1g4pp9dX1/Pggmyn2X8UhiPE/FwmHhnp/PqaCO+Zwfx5h1OmLbtcV7trcRD7cRDncS7uoh3dRPviRALx4hHjBOuUQ/xiAE7VC8nP/FyGL8PT0EQT2ERnqJiPIWFeAsL8RcU4CksHPAqwFNQyNoN73HU/PmJgPRhfN70aY+3vywRqMlpjycZsmnL+5Z5va720ERE3DChw9jGYslhr7Thq4FDWwOGywYNf0UyD5UNdWzM9nZjuzqI93Rhe8LEeqJZ9jwBj8Ub8OAJePHk5+EJluAtK8BfWIinuBhPcRmekgo8ZZPwlEzCU1SUHqaJsDUFBc57ILDX+623vp4S9SREREZNToRxz/r1lN59N1sffXT4Y0SR9GXEsjwbNxs+n3O2Z6YTR7xg4t2YWCeecDsm2oHHZzElFk9VHp5gAZ6iQqdnWlyKp6QcT9lkPGWVeMqr8EyqxjOpBs/kGjz5+SO3RUREDio5Eca2qwvf1q1E2jvSQtBTVJhyOcSASx9GuqwibZ0ByzMFbt8JHfEY7FoDW16Bra847+3bnGWBYpixBGacCDNPhJrjnLN+RURkQsuJMA4ecwx7/vEfme/G0Gm4Ezb/Gba+CltWwNaVzqU8AMXVTujO/JDzXnWU8+QRERGRFDkRxmOqY1d/j3fLK7DjzcTNJwxMORIWfCYRvidA6QzdCUlEREakMB6OtdC03unxbkn0fFs2Oct8+VCzGD5yndPrnb4EgmWuNldERA5OCuNU0V7Y/tf+Xu/WV6C7xVlWMNkJ3SWXOz3fqQucWx6KiIjsp4kdxl3NiWO9ifDd/lfnIQEAkw6F2o87wTvjRJh0iIacRUTkgJg4YWwttGxOBO8KJ4Qb1znLPH6oPgZOuMIJ3hknQFGlm60VEZEJJHfDOBaFnW+lX2IU2uUsyyt1TrCaf4HT86051nmqj4iIiAtyJoy90S7Y8Mf+S4waVkGky1lYNhPmnJK4zOhEqJy3z4+1ExERGW25EcbvPcdHXrwEXoyD8UDV0bDoUqf3O+NEKK1xu4UiIiJDyo0wnjqfD2ZdwOyTL3IuMcordrtFIiIiWcuNsdriKjbP+SwccpqCWEREDjq5EcYiIiIHsazC2BhzljHmXWPMBmPMtzIsLzXG/M4Y86YxZo0xZtnoN1VERCQ3jRjGxhgvcDvwUeBI4GJjzJEDqn0FeMdauxCoA24zxuj2VCIiIlnIpmd8PLDBWrvRWhsGHgLOG1DHAsXGGAMUAc1AdFRbKiIikqOyOZu6BtiaMt8AnDCgzi+AJ4DtQDFwobU2PnBDxpgrgCsAqqqqqK+v34cmZxYKhUZ1ezI07euxof08NrSfx4b28/CyCeNMN2S2A+bPBN4ATgMOAZ41xvzZWtuetpK1dwF3ASxevNjWjeLzh+vr6xnN7cnQtK/Hhvbz2NB+Hhvaz8PLZpi6AZiRMj8dpwecahnwW+vYAGwCakeniSIiIrktmzBeCRxmjJmTOCnrIpwh6VRbgNMBjDFVwBHAxtFsqIiISK4acZjaWhs1xlwN/AHwAvdYa9cYY65MLL8TuAm4zxizGmdY+3prbdMBbLeIiEjOyOp2mNbap4GnB5TdmTK9HThjdJsmIiIyMegOXCIiIi5TGIuIiLhMYSwiIuIyhbGIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLlMYi4iIuExhLCIi4jKFsYiIiMsUxiIiIi5TGIuIiLhMYSwiIuIyhbGIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLlMYi4iIuExhLCIi4jKFsYiIiMsUxiIiIi5TGIuIiLhMYSwiIuIyhbGIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLlMYi4iIuExhLCIi4jKFsYiIiMsUxiIiIi5TGIuIiLhMYSwiIuIyhbGIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLssqjI0xZxlj3jXGbDDGfGuIOnXGmDeMMWuMMX8a3WaKiIjkLt9IFYwxXuB24P8BDcBKY8wT1tp3UuqUAb8EzrLWbjHGTDlA7RUREck52fSMjwc2WGs3WmvDwEPAeQPqfBb4rbV2C4C1dvfoNlNERCR3ZRPGNcDWlPmGRFmqw4FyY0y9MeY1Y8znR6uBIiIiuW7EYWrAZCizGbZzHHA6EARWGGNesdauT9uQMVcAVwBUVVVRX1+/1w0eSigUGtXtydC0r8eG9vPY0H4eG9rPw8smjBuAGSnz04HtGeo0WWs7gU5jzAvAQiAtjK21dwF3ASxevNjW1dXtY7MHq6+vZzS3J0PTvh4b2s9jQ/t5bGg/Dy+bYeqVwGHGmDnGmABwEfDEgDr/C5xkjPEZYwqAE4C1o9tUERGR3DRiz9haGzXGXA38AfAC91hr1xhjrkwsv9Nau9YY8wzwFhAH7rbWvn0gGy4iIpIrshmmxlr7NPD0gLI7B8zfCtw6ek0TERGZGHQHLhEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUREXKYwFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxWU6EcW80xu/eD9MTibndFBERkb2WE2H85/VNPPZehPN/+TKbmzrdbo6IiMheyYkw/psjq/jqsXlsa+3mnJ+/yO9X73C7SSIiIlnLiTAGOGaKj6eu/QhzpxTx5Qde5x9/t4ZwNO52s0REREaUM2EMML28gP/v7z7EZUtnc+9Lm/nMr1awrbXb7WaJiIgMK6fCGCDg83DjuUfxy0uOZcPuEB//2Z9Zvm63280SEREZUs6FcZ+PzZ/G7675CNNKgyy7byW3PLOOaEzD1iIiMv7kbBgDzJlcyONXLeWiJTP4Zf37XHL3q+xu73G7WSIiImlyOowB8v1efvSpBdx2wULeamjjYz97kZffb3K7WSIiIkk5H8Z9PnXcdP736g9TGvTxubtf5RfPv0c8bt1uloiIyMQJY4DDq4p54uqPcM7Can78f+tZdt9KmjvDbjdLREQmuAkVxgCFeT7+/cJjuPkTR7Pi/T18/Gd/5rUPWtxuloiITGATLowBjDF87sRZ/Paqpfi8hgt/tYK7/7wRazVsLSIiY29ChnGfo2tKefKakzitdgo3P7WWK3/zGm3dEbebJSIiE8yEDmOA0qCfX116HN/9+Dz+uHY35/z8Rd7e1uZ2s0REZAKZ8GEMzrD1F0+ay8N/dyKRWJzz73iZB179QMPWIiIyJhTGKY6bVcFT157EiXMn8Z3H3+a6h9+gszfqdrNERCTHKYwHqCgMcN9lS/iH/3c4T7y5nfNuf4n3dnW43SwREclhCuMMPB7DNacfxm8uP4HWrjDn/uIlfvt6g9vNEhGRHKUwHsbSQyfz9LUnMX96KV975E1u+O1b9ERibjdLRERyjMJ4BFNK8nnwiydwVd0h/PdftnL+L19mc1On280SEZEcojDOgs/r4Ztn1XLPZYvZ1trN2T9/kd+v3uF2s0REJEcojPfCabVVPHXtRzh0ShFffuB1/vF3awhH9YxkERHZPwrjvTS9vIBH/u5DLPvwbO59aTOf+dUKtrV2u90sERE5iCmM90HA5+EH5xzFLy85lg27Q3z8Z39m+brdbjdLREQOUgrj/fCx+dN48pqPMK00yLL7VnLLM+uIxjRsLSIieyerMDbGnGWMedcYs8EY861h6i0xxsSMMZ8evSaOb7MnF/L4VUu5aMkMfln/Ppfc/Sq723vcbpaIiBxERgxjY4wXuB34KHAkcLEx5sgh6v0r8IfRbuR4l+/38qNPLeC2CxbyVkMbH/vZi7z8fpPbzRIRkYNENj3j44EN1tqN1tow8BBwXoZ61wCPARP24OmnjpvO/179YUqDPj5396v8/I/vEY/rYRMiIjK8bMK4BtiaMt+QKEsyxtQAnwTuHL2mHZwOryrmias/wjkLq7nt2fUsu28lzZ1ht5slIiLjmC+LOiZD2cDu3r8D11trY8Zkqp7YkDFXAFcAVFVVUV9fn10rsxAKhUZ1e/vrE1WWsiMDPLC2kb+59TmuWpjHoeVet5s1Ksbbvs5V2s9jQ/t5bGg/D8+M9MxeY8yHgButtWcm5m8AsNb+S0qdTfSH9mSgC7jCWvs/Q2138eLFdtWqVfvV+D6RWIRn65/lo6d9lOG+DLjh7W1tXPXA62xv7eZbH63l8o/MGXdt3Fv19fXU1dW53Yycp/08NrSfx4b2s8MY85q1dvHA8mx6xiuBw4wxc4BtwEXAZ1MrWGvnpHzQfcCTwwXxaHuz8U2ub7iem/77JqYVTaOmsMZ5L6phWmHivWga5XnlYx6ER9eU8rtrPsI3H32Tm59ay8rNzdzy6YWUBv1j2g4RERm/Rgxja23UGHM1zlnSXuAea+0aY8yVieWuHyeuLqrmE+WfIFgVZEdoB9s6t7Fy10o6I+kPdAj6gkwrnEZ1UTXVhdVUF1Ung7qmqIZJ+ZMOSFiXBv3c+bnj+M8XN/Gj36/jnJ+/yC8vOZaja0pH/bNEROTgk03PGGvt08DTA8oyhrC19rL9b9beqS6q5vSS06k7oS61HbSH29nRuYNtoW1OSIe2saNzB9tD21ndtJq23ra07QQ8AaqLqvsDu++VCO7KYCVez74d9zXG8MWT5rJoZjlXP/g659/xMt8/+0guPn4mXs/BPWwtIiL7J6swPhgZYyjNK6U0r5TaitqMdTojnWwPbXdendv7p0PbWb51Oc09zWn1fcbH1MKpg0K671VVUIXPM/wuPW5WOU9dexJfffgNvvs/b/Ovv1/HcbPLOX5OBSfMqWB+TRkBn26MJiIykeRsGGej0F/IYeWHcVj5YRmXd0e7kz3ptFfndl7a9hKN3Y1p9b3Gy5SCKRmDurqwmqmFUwl4A1QUBrjvsiX8/u2dvPR+E3/Z1Ez9u+8CkOfzsGhmGcfPruD4OZM4dlYZBYEJ/WsSEcl5+is/jKAvyNzSucwtnZtxeW+sl52dOzP2rlftWsWuTbuI2/57VRsMlcFKZyg8cZx64bypnLl4KkHPLBoa81i9JcyqD1r4xfINxJ/fgM9jOKqmlBPmVLBkdgVLZpdTVhAYq10gIiJjQGG8H/K8ecwqmcWsklkZl0fiEXZ37R7Uq94e2s7qxtU8u/lZojaatk7QF2TqjKnUHVaFL15OV3cxu5rz+fVfA9z9SgnxSBlHTJnE8XMqkq+qkvyx+HFFROQAURgfQH6Pn5qiGmqKajIuj8Vj7OnZw47OHezs3Jl87eraxc7Onezo3MCe7j3YgCUwHfr6w7tsAY/vLuXRhlLiy8so9U/m0IrpLKqew8lzDmVR9WwCPvWeRUQOFgpjF3k9zjHmKQVTWFi5MGOdSCySDOedXf2BvSO0g81t29ndtYbueAerw7B6M9y/GbCGgCmhIm8Ks0qrObRiOtOKpjG1cKrzKpjK5ODkfT4zXERERpfCeJzze/1ML57O9OLpQ9bpinSxM7ST17ZvYmXDRtY1bmVr+w4aQnvY1r6WV3euAE/6/bF9xkdlQWUynKcWJd4L+19u3CRFRGQiUhjngAJ/AXPL5zK3fC4XHHU64Fxn3dDSzV82NfPqxj38Zcs2trRvx/jbyMtrZ8qkHgrjnXT2tPJW12qe2/IckXgkbbt53rxkWFcVViVDelvXNoI7ghQFiijxl1AcKKYoUDTiZV0i40k0HmVH5w72RPdgrdUXT3GV/nrmKGMMMyoKmFFRwKeOmw4sZHdHDys3tbByczOvbmrmjffasRb8XsP86SXMn+ljTlWYirIu2sNNaUPjr+x4habupuTZ4f/5f/856DMLfAUUB4opDhRTEihJTmcqK/IXpc8HivB7dItQGV3ReJQdoR180PEBW9q3sKVjC1vat7C1YysNoQaicecEytseuo3ailpqK2qZVzGP2opa5pTO0RdMGTP6lzaBTCnO5+MLpvHxBdMAaOuO8NoHTjCv3NTMAy81E41bjIF5U2dx/JxFnDangiXHVlBZnEc0HqWpu4nnXnqOIxYcQUe4g45wB6FIiPZwe3K+77W7azcbWjck66Re5pVJ0BfMHOT+/jAvChRlDnx/MX6vwnwiisQjbA9tTwvbvvftoe1pVywU+AqYWTKTw8sP529m/Q0zi2eyZt0a4pPjrGtexyPvPkJvrBdwRoYOKzuM2kn9AX1Y+WEEfUG3flTJYQrjCaw06Oe02ipOq60CoDsc469bW/jLpmb+sqmZh1Zu4b6XNwMwd3Ihxyeudba91cyfdCz5/uxPAIvbOF2RLieoI+mhnSnIO8IdNHY1srF1I6FIiI5wBzEbG/Yzgr5gMriH6pUn3/NKBpV5jO58Nl5F4hG2dWxLD9uUwE39t1HoL2Rm8UzmTZrHmbPPZGbJTGYWz2RmycyM958v31ZO3YfqAKcnvbltM2ub17KueR3rmtfxh81/4NH1jwLgMR7mlMxJC+jailpK83Sfedk/CmNJCga8LD1kMksPmQxAOBrn7e1trEyE89Ord/DQyq0AfP/lZ5hRXsAhlYUcUlnEoVOKOGRKEYdWFlFeOPiyKo/xUBQooihQxDSm7XXbrLV0R7sHBfegIE8J+uaeZj5o/yBZZ7gwNxhn6DyvP6BTwzq1PLWsr17Aq0vJ9lckFqEh1MDWjq180J4+rLyjc0fa76/IX8TMkpkcNekozpp9FrNKZiVDtyK/Yp+P//o8Pg4tP5RDyw/lnEPOAZx/e9s7t7Nuz7pkSK/auYqnNj6VXK+6sDoZzLUVtcybNI+qgiodh5asKYxlSAGfh2NnlnPszHL+7pRDiMct7+0O8T/LXyWvciYbdod4v7GTl9/fQ2+0fwi6ojDAIZWFTkBXFiXDuqYsiGcfH4phjKHAX0CBv4CphVP3en1rLV1Rp2fe1tuWDPK+oG4Pt9Pe254W8JvbNztlkQ66o93Dbj/Pm5ce4Bl63gMDvK+s0F84Yf5oh2NhGkINTtAOGFbe0bkj7VBGsb+YmSUzmT95Ph+f+/G0Hu5YnulvjEneL+D0Wacny5t7mpO9576gXr51ORbnGfHleeUcUXFEfw96Ui2zimfpkkLJSGEsWfN4DEdMLeaEaT7q6g5Plsfilu2t3WxoDPH+7hDvN4Z4f3cnf1izi+bOrcl6eT4PcyuL0nvTlUXMrSzcqyHvfWGModBfSKG/cJ/CPBwLpwV3R7iD9t4BYZ5S3tjVyPut79MebicUDiX/QGfiMZ6MvfHWplaWv7wcn/Hh8/jwerz4PD58xoff4+8vSyz3eVLKjTdZlnwZ3+CyocpTyvZ2+L431su2jm1O7zYlbLd2bB0cuIFiZhXPYkHlAs455Jxk2M4snklZXtm4/pJSkV/B0uqlLK1emizrinSxvmV9sge9ds9afrP2N8krFYK+IIeXH95/otikWg4rO0wjK6Iwlv3n9fSfuX3qEVPSljV3hhPh7IT0ht0h3mpo46nVO7CJfDIGppcHnYCudIa7+8K6IsOQtxsC3gCTg5OZHJy81+vGbdw5yW1Az7uvN94X5KnlOzt30t7TzuaGzURtlEg8QiweIxqPErXREU+GG00e40n7QuD3+AcFeN+XgtbeVnZ27kz78lGaV8rM4pkcM+UYzi0+lxnFM5xh5eKZlOWXjdnPMRYK/AUcM+UYjplyTLIsEouwsW1jWkA/ufFJHn73YcC55n9u2dy0M7lrK2opChS59FOIGxTGckBVFAaoKHRO/ErVE4mxqakzGdDvN3ayYXeIFQOGvMsL/IOGuw+pLKKmPHjQPAfaYzzJXu/eqK+vp66uLuOyuI07wZwI5+T0MGUxGyMSjwwq65vuW5Zaliy30f4vA8N85tyyucwqnpU2pDzRT27ye/0cUXEER1QckSyL2zgNHQ39Ad28lpe2vcQT7z+RrDOjeEZaQM+bNG+fvgzKwUFhLK7I93uZN62EedPSAyoet2zLMOT97Du7eGjAkPecyYXJk8ac3rQz/H2gh7zHA4/xEPAGNLx5kPIYj/OFpWQmZ84+M1ne2NWYdib32j1refaDZ5PLJwcnU1tRm7zffczGsNYSt3HiNo7FmU4tz1QWJ5623sD1rbXEbCytLFO91LrWWuL0l8WJE4/Hk2WxWIy8/87LOLIy8DBLct74h10+8LBNxuUp2/J7h/7svvWT20jUG6tzOhTGMq54hhnybkkMeW/oC+nGTlY3tPH0gCHvmrLgoN709PIgU4rz8Hl1+ZKMX5UFlVQWVHLy9JOTZR3hjv4TxRK96Leb3sZjPM4LD8aY5LzB4PV4MaSUGYMHT/86Gcp8Ht+I9YwxeI23//NSPjtZPkTZlq1bmFYzLW1kZeBITd98b7SXznhn2ghMJB4ZVH8sDtu8dPFLez2qtS8UxnLQKC8MsLiwgsUZhrw373GGud/f3ZnsVb+ycQ89kf7/pB4DlcV5TC0NMq0kn6mlzmtaaT5TS/KZVhpkSknehOhZy8GjOFDMkqlLWDJ1idtN2S/1nfXUnVB3QLbdd9imL6yHCu1ILDLiF4GBh2KC3rG5yYvCWA56+X4vtVNLqJ2aecj7/cYQ21t72NnWzY62Hna29/B+Y4iXNjTR0RsdtL1JhQGqShIh3RfWpUGmleYnywvz9F9HZLzIhcM2+osiOSt1yHsoHT0RdrX3OCGdeO1od963t/Xw+pYWWroig9Yrzvf1h3RKL7svvKeVBCkJ+sb1pTkiMn4ojGVCK873U5zv59ApxUPW6YnE0gLbeXd62bvae1i3o53GUG/yuHWfoN+b7F1PLRncy55amk9FQWCfb4QiIrlDYSwygny/l1mTCpk1qXDIOpFYnN0dvf1D4QN62a9uamZXew/ReHpi+70mZUg8mDx+PbU0n20tMebu6aKyOI9gQMexRXKZwlhkFPi9HmrKgtSUDX2yRzxuaersTeldp/eyVze08n9retKus/7hq8sBKMrzUVmcR2VRHpOLA1QW5Tnzfa+ifCqL85hUFMCvM8ZFDjoKY5Ex4vEYphTnM6U4nwXTM9ex1tLaFWF7Wzd/fGkl0+YcQWOol8aOXppCYRo7enh3ZwcvdjTR3jP45DNwbrQyUmhXFudRFvRriFxknFAYi4wjxhjKCwOUFwZorPRRt3jGkHV7IjGaEkHd2NGbEtr9Za9taWF3e29ab7uPz2OYVBRI9rj7AzuPyuL+0J5cFKAoTyejiRxICmORg1S+38v08gKmlw99tjg4ve1Qb3TY0G4M9fLOjnaaQmFi8cEPtcj3ezKEdnpgO++6TltkXyiMRXKcMSZ51vjcyuEfPhCPW1q6wsnAzhTam5o6+cum5oyXfIFzq9LyggBlBX7nFQxQXuinrCBAWdBPeUGA0gL/oDoBn451y8SlMBaRJI/HMKkoj0lFedSO8KTJcDTOns6UoO7opbkrTGtXhNauMC2J9/cbQ7R84EwPPJs8VWHA6wT2gKAuLwhQGkwtC1CeeC8N+g+aB4aIDEdhLCL7JODzMK00yLTS7G4XaK2lMxyjpTNMW3eElpTgbu2KJMO7NbFse2s3LV1O3WEynJJ8H+WFgZSetz9DqPf3yssK/RTrGLiMMwpjERkTxhiK8nwU5fkY+rS0weJxS0dP1AnvRFC3dTnvLV0R2vp64YllG5tCtHZF6BjibHNwnsFdFvRTWuDHE+nmvzavTAZ4WdBPWaET3qk987ICv05kkwNGYSwi45rHYygtcIJzb0Rj8UQPPEJbd5iWzkiyp93fK4+wabtznfe6nR20doXpDMeG3KbPYygr8KcNm5cG+4bN/ZT2DaEHU46HFwQoDHgV4jIshbGI5CSf15M8/j2c+vp66upOSs73RmO0dUcSve/+ofPU4fS2bmd6W2sP72xvp7U7QtcwIe73GkqDfUPn/rTpsgHHxEuDfmfYPeinQCE+YSiMRURS5Pm8TCn2MqU4f6/W64nEaO9ODJd3pgd42nRXhIaWLtZsd6a7I0OHeMDrobRv6Dzl2Hdp0Dk7vijfR3G+j5J8nzOf58w7Z8/7yPN5FOYHiXEVxpFIhIaGBnp6evZ63dLSUtauXXsAWjVx5efnM336dPz+vRseFJmI8v1e8v1eppTsfYi3dUcSve6Uk9oSZf2BHmZrcxeruyK0dQ8f4n38XpMM5oFBXZzXP12UUl6S76MoL1En30dhwKc7tY2BcRXGDQ0NFBcXM3v27L3+NtfR0UFx8dBP3pG9Y61lz549NDQ0MGfOHLebI5Kz+kK8ai9DPBKLE+qJEuqN0t7jnLAW6onS0etM978iyfdQb5StzV1p88OdqQ5gDBQF+oO8rzeeHuq+AaHfH+Z90zK8cbWHenp69imIZfQZY5g0aRKNjY1uN0VEMvB7Pclbp+6rvsvNOnoihHqitKeEdHqQp8/vCYXZ3NTplPVGCWe43epAAQ+UvvRcovftT76XBBOBnQj1ksQQ/MB6Rfm+nL6mfFyFMaAgHkf0uxDJbamXm1G679vpjcaSgR1KhHZ7otfeF+DvvLeRssopdPQ4Pfn2nijbWrud+e5IxvunD9Q/1N4f1MWpgd43nxrkwf7y8XxW+7gLY7cVFRURCoXcboaIyEEjz+clr8jL5GHOXK/3bqOubsGQy8PReDLEU4fW27v7h+H7grxveWOol419PfSeCJHY8GPuHsOg0E6GdzB9aL0vzE+cO2lMbtWqMBYREdcFfNldijYUay09kfRATw329u5I2lB7au98XU+E9u7Mx9DfuvEMhbGbrLV885vf5Pe//z3GGL773e9y4YUXsmPHDi688ELa29uJRqPccccdLF26lMsvv5xVq1ZhjOFv//Zvue6669z+EUREJgxjDMGAl2DAy5SSfdtG3zH01OAuCoxNTI7bMP7H363hne3tWdePxWJ4vcM/uu3I6hJ+cM5RWW3vt7/9LW+88QZvvvkmTU1NLFmyhJNPPpkHH3yQM888k+985zvEYjG6urp444032LZtG2+//TYAra2tWbdbRETGh7Rj6GNMzywbwosvvsjFF1+M1+ulqqqKU045hZUrV7JkyRLuvfdebrzxRlavXk1xcTFz585l48aNXHPNNTzzzDOUlOzj1zIREZmQxm3PONsebJ/Rvs7Y2swnApx88sm88MILPPXUU1x66aV84xvf4POf/zxvvvkmf/jDH7j99tt55JFHuOeee0atLSIiktvUMx7CySefzMMPP0wsFqOxsZEXXniB448/ng8++IApU6bwpS99icsvv5zXX3+dpqYm4vE4n/rUp7jpppt4/fXX3W6+iIgcRMZtz9htn/zkJ1mxYgULFy7EGMMtt9zC1KlT+fWvf82tt96K3++nqKiI+++/n23btrFs2TLicec6uX/5l39xufUiInIwySqMjTFnAT8FvMDd1tofDVh+CXB9YjYEfNla++ZoNnSs9F1jbIzh1ltv5dZbb01b/oUvfIEvfOELg9ZTb1hERPbViMPUxhgvcDvwUeBI4GJjzJEDqm0CTrHWLgBuAu4a7YaKiIjkqmyOGR8PbLDWbrTWhoGHgPNSK1hrX7bWtiRmXwGmj24zRUREclc2w9Q1wNaU+QbghGHqXw78PtMCY8wVwBUAVVVV1NfXpy0vLS2lo6MjiyYNFovF9nldGVpPT8+g31MoFBpUJqNP+3lsaD+PDe3n4WUTxpnuqp3xuh9jzKk4YfyRTMuttXeRGMJevHixraurS1u+du3afb48SY9QPDDy8/NZtGhRWll9fT0Df3cy+rSfx4b289jQfh5eNmHcAMxImZ8ObB9YyRizALgb+Ki1ds/oNE9ERCT3ZXPMeCVwmDFmjjEmAFwEPJFawRgzE/gtcKm1dv3oN1NERCR3jdgzttZGjTFXA3/AubTpHmvtGmPMlYnldwLfByYBv0w8KzJqrV184JotIiKSO7K6ztha+zTw9ICyO1Omvwh8cXSbltui0Sg+n+65IiIiuh1mRp/4xCc47rjjOOqoo7jrLueS6WeeeYZjjz2WhQsXcvrppwPO2YHLli1j/vz5LFiwgMceewyAoqKi5LYeffRRLrvsMgAuu+wyvva1r3Hqqady/fXX85e//IWlS5eyaNEili5dyrvvvgs4Z4Z//etfT2735z//OX/84x/55Cc/mdzus88+y/nnnz8Wu0NERA6w8ds1+/23YOfqrKsHY1HwjvDjTJ0PH/3R8HWAe+65h4qKCrq7u1myZAnnnXceX/rSl3jhhReYM2cOzc3NANx0002UlpayerXTzpaWluE2C8D69et57rnn8Hq9tLe388ILL+Dz+Xjuuef49re/zWOPPcZdd93Fpk2b+Otf/4rP56O5uZny8nK+8pWv0NjYSGVlJffeey/Lli0beceIiMi4N37D2EU/+9nPePzxxwHYunUrd911FyeffDJz5swBoKKiAoDnnnuOhx56KLleeXn5iNu+4IILks9dbmtr4wtf+ALvvfcexhgikUhyu1deeWVyGLvv8y699FJ+85vfsGzZMlasWMH9998/Sj+xiIi4afyGcRY92FTdo3SdcX19Pc899xwrVqygoKCAuro6Fi5cmBxCTmWtJXHCWprUsp6enrRlhYWFyenvfe97nHrqqTz++ONs3rw5eQ3eUNtdtmwZ55xzDvn5+VxwwQU65iwikiN0zHiAtrY2ysvLKSgoYN26dbzyyiv09vbypz/9iU2bNgEkh6nPOOMMfvGLXyTX7RumrqqqYu3atcTj8WQPe6jPqqmpAeC+++5Llp9xxhnceeedRKPRtM+rrq6murqam2++OXkcWkREDn4K4wHOOussotEoCxYs4Hvf+x4nnngilZWV3HXXXZx//vksXLiQCy+8EIDvfve7tLS0cPTRR7Nw4UKWL18OwI9+9CPOPvtsTjvtNKZNmzbkZ33zm9/khhtu4MMf/jCxWCxZ/sUvfpGZM2eyYMECFi5cyIMPPphcdskllzBjxgyOPHLgszpERORgZazNeGfLA27x4sV21apVaWVr165l3rx5+7S9iXI7zKuvvppFixZx+eWXj8nnZfqd6LZ2Y0P7eWxoP48N7WeHMea1TPfh0EHHg8hxxx1HYWEht912m9tNERGRUaQwPoi89tprbjdBREQOAB0zFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwng/pD6daaDNmzdz9NFHj2FrRETkYKUwFhERcdm4vc74X//yr6xrXpd1/Vgslnwa0lBqK2q5/vjrh1x+/fXXM2vWLK666ioAbrzxRowxvPDCC7S0tBCJRLj55ps577zzsm4XOA+L+PKXv8yqVavw+Xz85Cc/4dRTT2XNmjUsW7aMcDhMPB7nscceo7q6ms985jM0NDQQi8X43ve+l7z9poiI5KZxG8ZuuOiii/jqV7+aDONHHnmEZ555huuuu46SkhKampo48cQTOffcczM+VWkot99+OwCrV69m3bp1nHHGGaxfv54777yTv//7v+eSSy4hHA4Ti8V4+umnqa6u5qmnngKch0mIiEhuG7dhPFwPNpPRuDf1okWL2L17N9u3b6exsZHy8nKmTZvGddddxwsvvIDH42Hbtm3s2rWLqVOnZr3dF198kWuuuQaA2tpaZs2axfr16/nQhz7ED3/4QxoaGjj//PM57LDDmD9/Pl//+te5/vrrOfvssznppJP262cSEZHxT8eMB/j0pz/No48+ysMPP8xFF13EAw88QGNjI6+99hpvvPEGVVVVg55RPJKhHsbx2c9+lieeeIJgMMiZZ57J888/z+GHH85rr73G/PnzueGGG/inf/qn0fixRERkHBu3PWO3XHTRRXzpS1+iqamJP/3pTzzyyCNMmTIFv9/P8uXL+eCDD/Z6myeffDIPPPAAp512GuvXr2fLli0cccQRbNy4kblz53LttdeyceNG3nrrLWpra6moqOBzn/scRUVFac85FhGR3KQwHuCoo46io6ODmpoapk2bxiWXXMI555zD4sWLOeaYY6itrd3rbV511VVceeWVzJ8/H5/Px3333UdeXh4PP/wwv/nNb/D7/UydOpXvf//7rFy5km984xt4PB78fj933HHHAfgpRURkPFEYZ7B69erk9OTJk1mxYkXGeqFQaMhtzJ49m7fffhuA/Pz8jD3cG264gRtuuCGt7Mwzz+TMM8/ch1aLiMjBSseMRUREXKae8X5avXo1l156aVpZXl4er776qkstEhGRg43CeD/Nnz+fN954w+1miIjIQUzD1CIiIi5TGIuIiLhMYSwiIuIyhbGIiIjLFMb7YbjnGYuIiGRLYZwDotGo200QEZH9MG4vbdr5z/9M79rsn2ccjcVoHuF5xnnzapn67W8PuXw0n2ccCoU477zzMq53//338+Mf/xhjDAsWLOC//uu/2LVrF1deeSUbN24E4I477qC6upqzzz47eSevH//4x4RCIW688Ubq6upYunQpL730Eueeey6HH344N998M+FwmEmTJvHAAw9QVVVFKBTimmuuYdWqVRhj+MEPfkBraytvv/02//Zv/wbAf/zHf7B27Vp+8pOfjLyjRURk1I3bMHbDaD7POD8/n8cff3zQeu+88w4//OEPeemll5g8eTLNzc0AXHvttZxyyik8/vjjxGIxQqEQLS0tw35Ga2srf/rTnwBoaWnhlVdewRjD3XffzS233MJtt93GTTfdRGlpafIWny0tLQQCARYsWMAtt9yC3+/n3nvv5Ve/+tX+7j4REdlH4zaMh+vBZjLenmdsreXb3/72oPWef/55Pv3pTzN58mQAKioqAHj++ee5//77AfB6vZSWlo4YxhdeeGFyuqGhgQsvvJAdO3YQDoeZM2cOAM899xwPPfRQsl55eTkAp512Gk8++STz5s0jEokwf/78vdxbIiIyWsZtGLul73nGO3fuHPQ8Y7/fz+zZs7N6nvFQ61lrR+xV9/H5fMTj8eT8wM8tLCxMTl9zzTV87Wtf49xzz6W+vp4bb7wRYMjP++IXv8g///M/U1tby7Jly7Jqj4iIHBg6gWuAiy66iIceeohHH32UT3/607S1te3T84yHWu/000/nkUceYc+ePQDJYerTTz89+bjEWCxGe3s7VVVV7N69mz179tDb28uTTz457OfV1NQA8Otf/zpZfsYZZ/CLX/wiOd/X2z7hhBPYunUrDz74IBdffHG2u0dERA4AhfEAmZ5nvGrVKhYvXswDDzyQ9fOMh1rvqKOO4jvf+Q6nnHIKCxcu5Gtf+xoAP/3pT1m+fDnz58/nuOOOY82aNfj9fr7//e9zwgkncPbZZw/72TfeeCMXXHABJ510UnIIHOC73/0uLS0tHH300SxcuJDly5cnl33mM5/hwx/+cHLoWkRE3GGsta588OLFi+2qVavSytauXcu8efP2aXujccx4ojn77LO57rrrOP3004esk+l3Ul9fT11d3QFunWg/jw3t57Gh/ewwxrxmrV08sFw94wmotbWVww8/nGAwOGwQi4jI2NAJXPvpYHyecVlZGevXr3e7GSIikqAw3k96nrGIiOyvcTdM7dYxbBlMvwsRkbExrsI4Pz+fPXv2KATGAWste/bsIT8/3+2miIjkvHE1TD19+nQaGhpobGzc63V7enoUHKMsPz+f6dOnu90MEZGcl1UYG2POAn4KeIG7rbU/GrDcJJZ/DOgCLrPWvr63jfH7/cnbOO6t+vp6Fi1atE/rioiIuGnEYWpjjBe4HfgocCRwsTHmyAHVPgoclnhdAdwxyu0UERHJWdkcMz4e2GCt3WitDQMPAQOfIXgecL91vAKUGWOmjXJbRUREclI2YVwDbE2Zb0iU7W0dERERySCbY8aZHjE08HTnbOpgjLkCZxgbIGSMeTeLz8/WZKBpFLcnQ9O+Hhvaz2ND+3lsaD87ZmUqzCaMG4AZKfPTge37UAdr7V3AXVl85l4zxqzKdL9PGX3a12ND+3lsaD+PDe3n4WUzTL0SOMwYM8cYEwAuAp4YUOcJ4PPGcSLQZq3dMcptFRERyUkj9oyttVFjzNXAH3AubbrHWrvGGHNlYvmdwNM4lzVtwLm0SU+rFxERyVJW1xlba5/GCdzUsjtTpi3wldFt2l47IMPfkpH29djQfh4b2s9jQ/t5GK49z1hEREQc4+re1CIiIhNRToSxMeYsY8y7xpgNxphvud2eXGSMmWGMWW6MWWuMWWOM+Xu325TLjDFeY8xfjTFPut2WXGaMKTPGPGqMWZf4t/0ht9uUi4wx1yX+brxtjPlvY4weJDDAQR/GWd6uU/ZfFPgHa+084ETgK9rPB9TfA2vdbsQE8FPgGWttLbAQ7fNRZ4ypAa4FFltrj8Y5Efgid1s1/hz0YUx2t+uU/WSt3dH38A9rbQfOHy3dZe0AMMZMBz4O3O12W3KZMaYEOBn4TwBrbdha2+pqo3KXDwgaY3xAARnuQzHR5UIY61acY8wYMxtYBLzqclNy1b8D3wTiLrcj180FGoF7E4cE7jbGFLrdqFxjrd0G/BjYAuzAuQ/F/7nbqvEnF8I4q1txyugwxhQBjwFftda2u92eXGOMORvYba19ze22TAA+4FjgDmvtIqAT0Dkno8wYU44zWjkHqAYKjTGfc7dV408uhHFWt+KU/WeM8eME8QPW2t+63Z4c9WHgXGPMZpxDLqcZY37jbpNyVgPQYK3tG+F5FCecZXT9DbDJWttorY0AvwWWutymcScXwjib23XKfjLGGJxja2uttT9xuz25ylp7g7V2urV2Ns6/5eettepFHADW2p3AVmPMEYmi04F3XGxSrtoCnGiMKUj8HTkdnSg3SFZ34BrPhrpdp8vNykUfBi4FVhtj3kiUfTtxdzaRg9U1wAOJL/Ib0a18R5219lVjzKPA6zhXZfwV3Y1rEN2BS0RExGW5MEwtIiJyUFMYi4iIuExhLCIi4jKFsYiIiMsUxiIiIi5TGIuIiLhMYSwiIuIyhbGIiIjL/n8rTC+lJXNvSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3301 - accuracy: 0.8846 - 173ms/epoch - 553us/step\n",
      "\n",
      "Test accuracy: 0.8845999836921692\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warning if any\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6156887e-06, 8.2255763e-10, 1.0061276e-07, 9.1485814e-09,\n",
       "       1.5020346e-06, 1.3485458e-04, 2.1938869e-05, 3.9495900e-03,\n",
       "       3.5419814e-07, 9.9588805e-01], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can read more on MNIST fashion example [here](https://www.tensorflow.org/tutorials/keras/classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California House Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to build a regression model for Califronia house pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(5160, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 867us/step - loss: 1.0225 - val_loss: 0.5308\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.5256 - val_loss: 0.4896\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.4779 - val_loss: 0.5104\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.4641 - val_loss: 0.4588\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.4509 - val_loss: 0.4466\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.4398 - val_loss: 0.5198\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 707us/step - loss: 0.4759 - val_loss: 0.4294\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.4306 - val_loss: 0.7459\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.4293 - val_loss: 0.4165\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 715us/step - loss: 0.4168 - val_loss: 0.4110\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.4207 - val_loss: 0.4192\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 729us/step - loss: 0.4069 - val_loss: 0.4048\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.4003 - val_loss: 0.3984\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.3981 - val_loss: 0.3945\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 715us/step - loss: 0.3940 - val_loss: 0.3918\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.3919 - val_loss: 0.3843\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3863 - val_loss: 0.3877\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.3868 - val_loss: 0.3840\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3822 - val_loss: 0.3794\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.3783 - val_loss: 0.3847\n"
     ]
    }
   ],
   "source": [
    "# build a regression NN\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # output layer with 1 neuron and with None activation function because it's regression\n",
    "])\n",
    "\n",
    "# compile NN\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 497us/step - loss: 0.4006\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8252645],\n",
       "       [2.118431 ],\n",
       "       [1.1086384]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the Sequential API or the Functional API, saving a trained Keras model is as simple as it gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will typically have a script that trains a model and saves it, and one or more scripts (or web services) that load the model and use it to make predictions. Loading the model is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if training lasts several hours? This is quite common, especially when training on large datasets.\n",
    "\n",
    "In this case, you should not only save your model at the end of training, but also save **checkpoints** at regular intervals during training, to avoid losing everything if your computer crashes.\n",
    "\n",
    "How can you tell the `fit()` method to save **checkpoints**? Use **callbacks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method accepts a `callbacks` argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. For example, the `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the `ModelCheckpoint` .\n",
    "\n",
    "In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darkc\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a simple way to implement **early stopping**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 917us/step - loss: 1.9680 - val_loss: 1.0162\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.8624 - val_loss: 0.7532\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.7162 - val_loss: 0.6708\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.6564 - val_loss: 0.6228\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.6150 - val_loss: 0.5844\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.5832 - val_loss: 0.5564\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.5567 - val_loss: 0.5341\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.5358 - val_loss: 0.5178\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.5188 - val_loss: 0.5023\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.5051 - val_loss: 0.4914\n"
     ]
    }
   ],
   "source": [
    "# train with callbacks and validation_data\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 584us/step - loss: 0.5202\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another way to implement **early stopping** is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the `patience` argument), and it will optionally roll back to the best model.\n",
    "\n",
    "> You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.4939 - val_loss: 0.4820\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.4849 - val_loss: 0.4751\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.4773 - val_loss: 0.4683\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4710 - val_loss: 0.4647\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.4654 - val_loss: 0.4605\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.4605 - val_loss: 0.4565\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.4563 - val_loss: 0.4527\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.4525 - val_loss: 0.4489\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.4489 - val_loss: 0.4471\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.4457 - val_loss: 0.4438\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.4433 - val_loss: 0.4411\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.4403 - val_loss: 0.4382\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.4380 - val_loss: 0.4360\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.4351 - val_loss: 0.4361\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.4334 - val_loss: 0.4293\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.4312 - val_loss: 0.4294\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.4293 - val_loss: 0.4260\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.4275 - val_loss: 0.4252\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.4254 - val_loss: 0.4255\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.4239 - val_loss: 0.4223\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.4222 - val_loss: 0.4214\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.4209 - val_loss: 0.4185\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.4191 - val_loss: 0.4153\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.4177 - val_loss: 0.4143\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.4164 - val_loss: 0.4131\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.4151 - val_loss: 0.4125\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.4138 - val_loss: 0.4125\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.4126 - val_loss: 0.4098\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.4115 - val_loss: 0.4088\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.4100 - val_loss: 0.4066\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.4090 - val_loss: 0.4077\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.4080 - val_loss: 0.4074\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.4069 - val_loss: 0.4029\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.4055 - val_loss: 0.4021\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 848us/step - loss: 0.4047 - val_loss: 0.4021\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.4035 - val_loss: 0.4002\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.4027 - val_loss: 0.3998\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.4017 - val_loss: 0.3991\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.4006 - val_loss: 0.3980\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.3996 - val_loss: 0.3980\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3987 - val_loss: 0.3951\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3978 - val_loss: 0.3953\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3967 - val_loss: 0.3947\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3959 - val_loss: 0.3926\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3951 - val_loss: 0.3925\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.3945 - val_loss: 0.3906\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3930 - val_loss: 0.3894\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 779us/step - loss: 0.3925 - val_loss: 0.3889\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.3915 - val_loss: 0.3875\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.3907 - val_loss: 0.3876\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3900 - val_loss: 0.3859\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.3891 - val_loss: 0.3859\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.3884 - val_loss: 0.3849\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3872 - val_loss: 0.3851\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.3868 - val_loss: 0.3836\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3857 - val_loss: 0.3823\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3852 - val_loss: 0.3820\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.3842 - val_loss: 0.3822\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.3835 - val_loss: 0.3802\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3827 - val_loss: 0.3801\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3822 - val_loss: 0.3788\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3812 - val_loss: 0.3785\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.3805 - val_loss: 0.3781\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3795 - val_loss: 0.3773\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.3794 - val_loss: 0.3763\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.3786 - val_loss: 0.3758\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3777 - val_loss: 0.3749\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.3771 - val_loss: 0.3746\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3763 - val_loss: 0.3752\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 763us/step - loss: 0.3757 - val_loss: 0.3749\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.3752 - val_loss: 0.3734\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.3743 - val_loss: 0.3732\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.3738 - val_loss: 0.3728\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.3731 - val_loss: 0.3721\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.3726 - val_loss: 0.3722\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3723 - val_loss: 0.3715\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.3710 - val_loss: 0.3706\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3708 - val_loss: 0.3707\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3704 - val_loss: 0.3690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.3692 - val_loss: 0.3701\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.3690 - val_loss: 0.3702\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.3685 - val_loss: 0.3688\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3683 - val_loss: 0.3675\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3673 - val_loss: 0.3675\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3671 - val_loss: 0.3667\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3662 - val_loss: 0.3673\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.3660 - val_loss: 0.3666\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.3650 - val_loss: 0.3666\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.3647 - val_loss: 0.3651\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 729us/step - loss: 0.3641 - val_loss: 0.3665\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.3637 - val_loss: 0.3648\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.3634 - val_loss: 0.3644\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3626 - val_loss: 0.3642\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3621 - val_loss: 0.3641\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.3617 - val_loss: 0.3637\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3609 - val_loss: 0.3628\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3607 - val_loss: 0.3628\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.3605 - val_loss: 0.3624\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3599 - val_loss: 0.3622\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.3594 - val_loss: 0.3621\n",
      "162/162 [==============================] - 0s 565us/step - loss: 0.3785\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you need extra control, you can easily write your own custom callbacks. As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect over‐fitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276/363 [=====================>........] - ETA: 0s - loss: 0.3590\n",
      "val/train: 1.01\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.3588 - val_loss: 0.3611\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neat feature of Tensorflow and Keras is visulaization through Tensorboard. The following code shows how you can visualize your training using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3584 - val_loss: 0.3624\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3578 - val_loss: 0.3614\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3570 - val_loss: 0.3614\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.3568 - val_loss: 0.3608\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3564 - val_loss: 0.3597\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 744us/step - loss: 0.3560 - val_loss: 0.3596\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.3557 - val_loss: 0.3588\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.3553 - val_loss: 0.3589\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3547 - val_loss: 0.3578\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3546 - val_loss: 0.3581\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3540 - val_loss: 0.3582\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.3534 - val_loss: 0.3563\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.3531 - val_loss: 0.3563\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3525 - val_loss: 0.3570\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.3524 - val_loss: 0.3554\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.3516 - val_loss: 0.3556\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3512 - val_loss: 0.3557\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.3506 - val_loss: 0.3583\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 729us/step - loss: 0.3508 - val_loss: 0.3550\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3498 - val_loss: 0.3564\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3497 - val_loss: 0.3546\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.3492 - val_loss: 0.3538\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3487 - val_loss: 0.3544\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3481 - val_loss: 0.3561\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.3484 - val_loss: 0.3525\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.3478 - val_loss: 0.3535\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3474 - val_loss: 0.3517\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.3470 - val_loss: 0.3513\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.3468 - val_loss: 0.3520\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 779us/step - loss: 0.3462 - val_loss: 0.3530\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard Visualization\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, run the following command at the root of the project directory where `my_logs` has been saved (or from anywhere else, as long as you point to the appropriate log directory):\n",
    "\n",
    "> `$ tensorboard --logdir=./my_logs --port=6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And finally, once the server is up, you can open a web browser and go to:\n",
    "\n",
    "> http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-1 has 10 points**.\n",
    "\n",
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "- Imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k and so on.\n",
    "\n",
    "- How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k.\n",
    "\n",
    "**Hint**: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data with at least 6 data points for x and y\n",
    "xs = np.array([1,2,3,4,5,6], dtype=float)\n",
    "ys = np.array([100, 150, 200, 250, 300, 350], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with one layer and one neuron\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for regression\n",
    "model.compile(optimizer=\"sgd\", loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 61193.2773\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28453.9004\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13300.1748\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6285.6226\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3038.1289\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1534.1538\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 837.1362\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 513.6091\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 362.9519\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 292.3111\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 258.7107\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 242.2601\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 233.7538\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 228.9305\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 225.8185\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 223.5051\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 221.5673\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 219.8097\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 218.1422\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 216.5222\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 214.9306\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 213.3581\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 211.8006\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 210.2562\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 208.7235\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 207.2026\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 205.6929\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 204.1943\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 202.7065\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 201.2298\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 199.7637\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 198.3082\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 196.8634\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.4292\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 194.0053\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 192.5920\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 191.1887\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 189.7959\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 188.4130\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 187.0403\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 185.6778\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 184.3248\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 182.9820\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 181.6489\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 180.3254\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 179.0116\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 177.7074\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 176.4129\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 175.1275\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 173.8516\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 172.5850\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 171.3277\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 170.0796\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 168.8403\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 167.6102\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 166.3891\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 165.1768\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 163.9735\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 162.7789\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 161.5929\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 160.4156\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 159.2469\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 158.0866\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 156.9350\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 155.7916\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 154.6565\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 153.5298\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 152.4112\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 151.3009\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 150.1986\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 149.1043\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 148.0180\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 146.9396\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 145.8691\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 144.8064\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 143.7513\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 142.7041\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 141.6643\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 140.6322\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 139.6077\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 138.5906\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 137.5809\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 136.5785\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 135.5835\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 134.5957\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 133.6150\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 132.6416\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 131.6752\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 130.7158\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 129.7635\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 128.8182\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 127.8797\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 126.9480\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 126.0231\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 125.1049\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 124.1934\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 123.2886\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 122.3903\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 121.4987\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 120.6135\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 119.7348\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 118.8625\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 117.9965\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 117.1368\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 116.2834\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 115.4362\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 114.5952\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 113.7604\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 112.9315\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 112.1087\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 111.2920\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 110.4813\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 109.6762\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 108.8772\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 108.0840\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 107.2965\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 106.5149\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 105.7387\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 104.9684\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 104.2036\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 103.4445\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 102.6909\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 101.9426\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 101.2000\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 100.4626\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 99.7308\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 99.0042\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 98.2828\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 97.5668\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 96.8560\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 96.1503\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 95.4498\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 94.7544\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 94.0641\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 93.3787\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 92.6985\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 92.0231\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 91.3526\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 90.6871\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 90.0264\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 89.3705\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 88.7194\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 88.0731\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 87.4313\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 86.7943\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 86.1620\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 85.5343\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 84.9111\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 84.2925\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 83.6784\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 83.0687\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 82.4635\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 81.8627\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 81.2663\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 80.6743\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 80.0864\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 79.5031\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 78.9238\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 78.3488\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 77.7779\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 77.2114\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 76.6488\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 76.0904\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 75.5360\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 74.9857\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 74.4394\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 73.8971\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 73.3586\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 72.8242\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 72.2936\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.7669\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.2441\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 70.7251\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 70.2097\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 69.6983\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 69.1905\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 68.6864\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 68.1859\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 67.6891\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 67.1960\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 66.7065\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 66.2204\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 65.7380\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 65.2591\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 64.7835\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 64.3117\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 63.8431\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 63.3779\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.9162\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.4579\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.0028\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 61.5511\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 61.1026\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 60.6574\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60.2155\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.7768\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.3414\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 58.9090\n",
      "Epoch 199/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 58.4799\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 58.0538\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 57.6308\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.2109\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 56.7940\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 56.3803\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.9695\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.5617\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.1569\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 54.7552\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 54.3561\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 53.9601\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 53.5671\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 53.1768\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.7894\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.4048\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.0230\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 51.6439\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 51.2677\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.8942\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 50.5234\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 50.1554\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 49.7899\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 49.4271\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 49.0670\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48.7096\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48.3547\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48.0023\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.6526\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 47.3055\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.9609\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 46.6187\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.2790\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.9418\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.6072\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.2749\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.9451\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.6176\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.2926\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.9699\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.6495\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 43.3315\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.0158\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.7024\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 42.3913\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.0824\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 41.7759\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.4715\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 41.1694\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.8695\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.5716\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.2761\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.9826\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.6914\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.4022\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.1150\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 38.8300\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 38.5472\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 38.2664\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.9876\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.7108\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.4360\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.1633\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.8925\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 36.6238\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.3570\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.0921\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.8291\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.5681\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.3090\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 35.0517\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 34.7964\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 34.5428\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.2911\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.0413\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 33.7933\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 33.5471\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 33.3027\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 33.0601\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 32.8192\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 32.5801\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.3427\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 32.1071\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.8732\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 31.6409\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.4104\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.1816\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.9545\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 30.7289\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 30.5051\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 30.2828\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 30.0621\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.8431\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.6257\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.4099\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.1956\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.9829\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.7718\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.5622\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.3540\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 28.1475\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 27.9424\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.7388\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.5368\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 27.3362\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 27.1370\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 26.9393\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.7430\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 26.5482\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.3547\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 26.1628\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.9721\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.7829\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 25.5951\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 25.4086\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.2235\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 25.0397\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 24.8573\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.6762\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.4964\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.3180\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.1407\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.9649\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.7903\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.6170\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.4449\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.2741\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.1046\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.9362\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.7691\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.6032\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.4385\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.2751\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.1127\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 21.9517\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.7918\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.6330\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.4754\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.3189\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.1636\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.0094\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.8563\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.7044\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.5535\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.4038\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.2551\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.1076\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9611\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8157\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6713\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.5279\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 19.3857\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2445\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1043\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.9651\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.8269\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6898\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.5536\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.4184\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.2842\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.1510\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.0188\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.8875\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.7572\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.6278\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.4994\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.3719\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.2454\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.1197\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.9950\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.8711\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.7482\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.6262\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5050\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.3848\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.2655\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.1470\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.0293\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.9125\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.7966\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.6815\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.5672\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.4538\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.3413\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.2295\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.1185\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.0084\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.8990\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.7905\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.6828\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.5758\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.4695\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.3641\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.2595\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.1556\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.0525\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.9501\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.8485\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.7476\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.6474\n",
      "Epoch 399/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 13.5480\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4493\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.3513\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.2540\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.1575\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.0616\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.9664\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.8720\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7782\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6851\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5927\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5009\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.4098\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.3194\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2297\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 12.1405\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0521\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9643\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8771\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7906\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7047\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.6195\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5348\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.4507\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3673\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2845\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2023\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1206\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.0396\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9592\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8794\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8001\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7214\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6433\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5658\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4888\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4124\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3365\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2612\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1865\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1122\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0386\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9654\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8928\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8208\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7492\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6781\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6077\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5377\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4682\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3992\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3307\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2627\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1952\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1283\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0618\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9957\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9302\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8651\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8005\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7364\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6728\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6096\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5468\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4846\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4228\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3615\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3005\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2400\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1800\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1204\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0612\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0025\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9442\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.8864\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8289\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7719\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7152\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6590\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6032\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5478\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4928\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4382\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3840\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3303\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2768\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2238\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1712\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1190\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0671\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0156\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9645\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9138\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8634\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8134\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7637\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7144\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6656\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6170\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5688\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5209\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4734\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4262\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3794\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3329\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2868\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2410\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1955\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1504\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1056\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0611\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0170\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9731\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9296\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8864\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8435\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8009\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7587\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7167\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6751\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6337\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5927\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5519\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5115\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4713\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4315\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3919\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3526\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3136\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2749\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2365\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1983\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1604\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1228\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0855\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0485\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0117\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9752\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9389\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9029\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8672\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8318\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7966\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.7616\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7269\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6925\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6583\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6244\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5907\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5572\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.5240\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4910\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4583\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4259\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3936\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3616\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3298\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2983\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.2670\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2359\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2050\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1744\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1440\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1138\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0838\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0540\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0245\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9952\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9661\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9372\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9085\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8800\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8518\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8237\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7959\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7682\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7407\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7135\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6864\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6596\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6329\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6064\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5802\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5541\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5282\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5025\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4770\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4516\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4265\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4015\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3767\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3521\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3277\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3035\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2794\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2555\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2318\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2082\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1849\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1617\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.1386\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1158\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0931\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0705\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0482\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0260\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0039\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9820\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9603\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9387\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9173\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8961\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8750\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8540\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8332\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8126\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7921\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7718\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7516\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7315\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7116\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6919\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6723\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6528\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6334\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6143\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5952\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5763\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5575\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5389\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5204\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5021\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4838\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4657\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4478\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4299\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4122\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3947\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3772\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3599\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3427\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3256\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3087\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2919\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2752\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2586\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2421\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2258\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2096\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1935\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1775\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1616\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1459\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.1303\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1147\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0993\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0840\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0688\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0538\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0388\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0240\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0092\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9946\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9800\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9656\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9513\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9371\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9230\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9090\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8951\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.8812\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8675\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8539\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8404\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8270\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8137\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8005\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7874\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7744\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7614\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7486\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7359\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7232\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7107\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6982\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6858\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6735\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6614\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6492\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6372\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6253\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6134\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6017\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5900\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5785\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5670\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5555\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5442\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5330\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5218\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5107\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4997\n",
      "Epoch 701/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4888\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4779\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4672\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4565\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4459\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4353\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4249\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4145\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4042\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3940\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3838\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3737\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3637\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3538\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3439\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3341\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3244\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3147\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3052\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2957\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2862\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2768\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2675\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2583\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2491\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2401\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2310\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2220\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2131\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2043\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1955\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1868\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1782\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1696\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1611\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1526\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1442\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1359\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1276\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1194\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1112\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1031\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0951\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0871\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0792\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0713\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0635\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0558\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0481\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0405\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0329\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0253\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0179\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0105\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0031\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9958\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9885\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9813\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9742\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9671\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9600\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9530\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9461\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9392\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9324\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9256\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9188\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9121\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9055\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8989\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8923\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8858\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8794\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8730\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8666\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8603\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8540\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8478\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8416\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8355\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8294\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8234\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8174\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8114\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8055\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7997\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7938\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7880\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7823\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7766\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7709\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7653\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7597\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7542\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7487\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7433\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7379\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7325\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7271\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7218\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7166\n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7114\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7062\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7010\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6959\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6909\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6858\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6808\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6759\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6709\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6661\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6612\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6564\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6516\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6469\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6421\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6375\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6328\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6282\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6236\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6191\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6146\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6101\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6057\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6012\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5969\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5925\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5882\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5839\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5797\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5754\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5712\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5671\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5629\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5589\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5548\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5507\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5427\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5388\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5349\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5310\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5271\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5233\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5194\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5157\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5119\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5082\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5045\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5008\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4972\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4935\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4899\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4864\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4828\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4793\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4758\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4723\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4621\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4554\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4521\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4488\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4455\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4423\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4390\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4358\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4327\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4295\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4264\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4233\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4202\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4171\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4141\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4111\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4081\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4051\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4022\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3992\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3963\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3934\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3906\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3877\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3849\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3821\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3793\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3765\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3738\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3711\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3684\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3657\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3630\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3604\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3578\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3551\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3526\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3500\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3474\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3449\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3424\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3399\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3374\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3350\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3325\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3301\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3277\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3253\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3229\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3206\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3182\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3159\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3136\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3113\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3091\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3068\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3046\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3024\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3002\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2980\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2958\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2937\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2915\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2894\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2873\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2852\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2831\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2790\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2770\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2750\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2729\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2710\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2690\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2670\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2651\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2632\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2612\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2593\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2556\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2537\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2500\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2482\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2464\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2446\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2428\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2410\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2393\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2375\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2358\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2341\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2324\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2307\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2290\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2273\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2257\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2240\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2224\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2208\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2192\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2176\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2160\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2144\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2129\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2113\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2098\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2082\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2067\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2052\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2037\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2008\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1993\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1979\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1964\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1950\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1936\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1922\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1907\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1894\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1880\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1866\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1853\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1839\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1826\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1812\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1799\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1786\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1773\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1760\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1747\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1735\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1722\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1709\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1697\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1685\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2387cf472b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 1000 epochs\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400.58987k\n"
     ]
    }
   ],
   "source": [
    "# predict the price for 7-bedroom house price\n",
    "print(str(model.predict([7.0])[0][0]) + \"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-2 has 20 points**.\n",
    "\n",
    "In this notebook you learned how to do classification using Fashion MNIST, a data set containing items of clothing, and a similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy using `callbacks`.\n",
    "\n",
    "- **Requirements**:\n",
    "1. It should succeed in less than 10 epochs.\n",
    "2. When it reaches 99% or greater it should print out the string `\"Reached 99% accuracy so cancelling training!\"` as specified in the `myCallback` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.99):\n",
    "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load data\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model - be careful about the activation functions of the hidden layer and output layer\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for multi-class classification, metrics should be 'accuracy'\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0445 - accuracy: 0.9858\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0432 - accuracy: 0.9855\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0401 - accuracy: 0.9864\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0358 - accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0359 - accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0337 - accuracy: 0.9886\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0311 - accuracy: 0.9898\n",
      "Epoch 8/10\n",
      "1839/1875 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9909\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0273 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2381c407eb0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 10 epochs (will stop earlier) and callbacks\n",
    "# Note: Your output should include the message: \"Reached 99% accuracy so cancelling training!\"\n",
    "# The output should also include:\n",
    "# <tensorflow.python.keras.callbacks.History at MEMORY_ADDRESS> \n",
    "endEarly = myCallback()\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[endEarly])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] - [Tensorflow Website](https://www.tensorflow.org/)\n",
    "- [2] - [Tensorflow Tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [3] - [Hands-On ML Textbook 2nd Edition](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "- [4] - [DeepLearning.AI TensorFlow Developer Professional Certificate - Course-1](https://www.coursera.org/professional-certificates/tensorflow-in-practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-tf-notebook.ipynb```. Submit the file using the ```tf-notebook``` link on Blackboard.\n",
    "\n",
    "- tf-notebook has a total of 30 points which will be counted towards the \"Assignment\" section of your final grade.\n",
    "\n",
    "- **RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO even if you've completed the exercises.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * verification of correct installation of Tensorflow\n",
    "  * error-free running of all the cells - all outputs and plots must be included - any missing output would cause the notebook to get ZERO!\n",
    "  * correct answers to the exercises - Exercise-1 [10 points], Exercise-2 [20 points]\n",
    "  \n",
    "<font color=red><b>Due Date: Tuesday April 19th, 11:59PM</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
